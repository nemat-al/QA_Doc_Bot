{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWCuJyJHIyOjyZjzWvq3ZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemat-al/QA_Doc_Bot/blob/main/QA_doc_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bot in Huggingface space: https://huggingface.co/spaces/nemat-al/QA_bot"
      ],
      "metadata": {
        "id": "D-QCvZo4ioci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community\n",
        "pip install lang chain_community\n",
        "pip install gradio\n",
        "pip install chromadb\n",
        "pip install pypdf"
      ],
      "metadata": {
        "id": "q_XrGcrKhxA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68-UyJv1hqKL"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "import gradio as gr\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import chromadb.api\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "chromadb.api.client.SharedSystemClient.clear_system_cache()\n",
        "def get_llm():\n",
        "    model_id = 'google/flan-t5-base'\n",
        "    hf_pipeline = pipeline(\"text2text-generation\", model=model_id, tokenizer=model_id)\n",
        "\n",
        "    # Wrap the pipeline in HuggingFacePipeline\n",
        "    llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "    return llm\n",
        "\n",
        "def hugging_face_embedding():\n",
        "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    return embedding_model\n",
        "\n",
        "def document_loader(file):\n",
        "    loader = PyPDFLoader(file.name)\n",
        "    loaded_document = loader.load()\n",
        "    return loaded_document\n",
        "\n",
        "def text_splitter(data):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50,\n",
        "        length_function=len,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "    return chunks\n",
        "\n",
        "def vector_database(chunks):\n",
        "    embedding_model = hugging_face_embedding()\n",
        "    vectordb = Chroma.from_documents(chunks, embedding_model)\n",
        "    return vectordb\n",
        "\n",
        "def retriever(file):\n",
        "    splits = document_loader(file)\n",
        "    chunks = text_splitter(splits)\n",
        "    vectordb = vector_database(chunks)\n",
        "    retriever = vectordb.as_retriever()\n",
        "    return retriever\n",
        "\n",
        "def retriever_qa(file, query):\n",
        "    llm = get_llm()\n",
        "    retriever_obj = retriever(file)\n",
        "    qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                    chain_type=\"stuff\",\n",
        "                                    retriever=retriever_obj,\n",
        "                                    return_source_documents=False)\n",
        "    response = qa.run(query)\n",
        "    return response\n",
        "\n",
        "rag_application = gr.Interface(\n",
        "    fn=retriever_qa,\n",
        "    inputs=[\n",
        "        gr.File(label=\"Upload PDF File\", file_count=\"single\", file_types=['.pdf'], type=\"filepath\"),\n",
        "        gr.Textbox(label=\"Input Query\", lines=2, placeholder=\"Type your question here...\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Output\"),\n",
        "    title=\"RAG Chatbot\",\n",
        "    description=\"Upload a PDF document and ask any question. The chatbot will try to answer using the provided document.\"\n",
        ")\n",
        "\n",
        "rag_application.launch(debug=True)\n"
      ]
    }
  ]
}